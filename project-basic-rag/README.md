ğŸ“„ Project 1 â€” Document Q&A System (Basic RAG with Local Embeddings)



<img width="1536" height="1024" alt="RAG_architecture" src="https://github.com/user-attachments/assets/2954d8d5-a90a-4b20-93af-b152053bf412" />

                                                    [âš™ï¸ Basic RAG Architecture]


ğŸš€ Introduction

This project implements a fully local Retrieval-Augmented Generation (RAG) document question-answering system, built using:

LlamaIndex for indexing & retrieval

HuggingFace BGE embeddings (offline, no API required)

Gradio for an easy interactive UI

Docker for containerized deployment

It demonstrates how to build a practical, production-ready, offline Q&A system â€” ideal for beginners, freshers, and engineers building hands-on projects for their portfolio.

ğŸ·ï¸ Tech Badges
<p> <img src="https://img.shields.io/badge/Python-3.10+-blue?logo=python" /> <img src="https://img.shields.io/badge/LlamaIndex-RAG-orange?logo=semanticweb" /> <img src="https://img.shields.io/badge/HuggingFace-Embeddings-yellow?logo=huggingface" /> <img src="https://img.shields.io/badge/Gradio-WebUI-green?logo=googlechrome" /> <img src="https://img.shields.io/badge/Docker-Containerized-blue?logo=docker" /> </p>

## ğŸ“‘ Table of Contents
- [Introduction](#introduction)
- [Architecture Diagram (Project 1)](#architecture-diagram-project-1)
- [Features](#features)
- [Project Structure](#project-structure)
- [Screenshots](#screenshots)
- [How to Run](#how-to-run)
- [How It Works](#how-it-works)
- [Purpose of This Project](#purpose-of-this-project)

ğŸš€ Features

ğŸ”¹ 1. Local Embedding-Based Search
Uses BAAI/bge-small-en-v1.5 for fully offline vector generation.

ğŸ”¹ 2. Document Indexing
Reads files â†’ embeds text â†’ stores in VectorStoreIndex.

ğŸ”¹ 3. Interactive Gradio UI
Upload â†’ Index â†’ Ask Questions â†’ Get Answers.

ğŸ”¹ 4. No LLM Required
Pure embedding retrieval:
âœ”ï¸ Fast âœ”ï¸ Free âœ”ï¸ Private âœ”ï¸ Offline

ğŸ”¹ 5. Docker Support
Build & run anywhere with one command.

project-basic-rag/
â”‚â”€â”€ app.py
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ docs/
â”‚â”€â”€ screenshots/
â”‚   â”œâ”€â”€ 01-folder-structure.png
â”‚   â”œâ”€â”€ 02-index-document.png
â”‚   â”œâ”€â”€ 03-indexed-status.png
â”‚   â”œâ”€â”€ 04-query-and-answer.png
â”‚   â”œâ”€â”€ RAG_architecture.png   <-- used in README


| Step                  | Image                                 |
| --------------------- | ------------------------------------- |
| ğŸ“ Project Structure  | `screenshots/01-folder-structure.png` |
| ğŸ“¤ Upload & Index     | `screenshots/02-index-document.png`   |
| ğŸ“Œ Index Confirmation | `screenshots/03-indexed-status.png`   |
| â“ Query & Response    | `screenshots/04-query-and-answer.png` |


2ï¸âƒ£ Start the App
python app.py


Access UI at: http://localhost:7860

3ï¸âƒ£ Run with Docker
docker build -t doc-qa-basic .
docker run -p 7860:7860 doc-qa-basic

ğŸ§  How It Works (High-Level Architecture)

Upload Document â†’ LlamaIndex reads text

Convert text into embeddings (BGE-small)

Store vectors in an index

Convert user question â†’ embedding

Perform similarity search

Return best-matching answer (pure retrieval)

ğŸ¯ Purpose of This Project

This project is designed to help you:

Understand core RAG workflows

Learn vector search, embeddings, and indexing

Build offline, local GenAI tools

Prepare for advanced RAG architectures

Strengthen your resume with practical AI/ML projects

Perfect for freshers & early-career engineers.

ğŸ§© Next Steps (Upcoming Projects)
Project	Description
Project 2	Multi-document RAG with metadata filtering
Project 3	Hybrid RAG + LLM (retrieval + generation)
Project 4	Enterprise vector DB (Pinecone / Chroma)
Project 5	Rerankers, chunking strategies, evaluation
